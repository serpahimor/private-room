{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import codecs\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['遍历', '语料', '中', '词语', '删除', '停', '用词']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "1. 文本切割\n",
    "\"\"\"\n",
    "\n",
    "def sent2word(sentence):\n",
    "    \"\"\"\n",
    "    Segment a sentence to words\n",
    "    Delete stopwords\n",
    "    \"\"\"\n",
    "    segList = jieba.cut(sentence)\n",
    "    segResult = []\n",
    "    for w in segList:\n",
    "        segResult.append(w)\n",
    "    stopwords = [line.strip() for line in io.open('stop_words.txt').readlines()]\n",
    "    newSent = []\n",
    "    for word in segResult:\n",
    "        if word in stopwords:\n",
    "            #print (\"stopword: %s\" % word)\n",
    "            continue\n",
    "        else:\n",
    "            newSent.append(word)\n",
    "    return newSent\n",
    "\n",
    "sent2word(\"总的来看总的来看遍历所有语料中的所有词语，删除其中的停用词。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='BosonNLP_sentiment_score.txt' mode='r+' encoding='utf-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3ba3ef34e051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#classifyWords(sent2word(\"总的来看总的来看遍历所有语料中的所有词语，删除其中的停用词。\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mclassify_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent2word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"总的来看总的来看遍历所有语料中的所有词语，删除其中的停用词。\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-3ba3ef34e051>\u001b[0m in \u001b[0;36mclassify_words\u001b[1;34m(word_dict)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msen_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# 每一行内容根据空格分割，索引0是情感词，索引1是情感分值（情感词典文件中有一行是空行，因此执行的时候会报错，注意处理一下空行，这里没有处理）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msen_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# 读取否定词文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def classify_words(word_dict):  \n",
    "    \"\"\"词语分类,找出情感词、否定词、程度副词\"\"\"  \n",
    "    # 读取情感字典文件  \n",
    "    sen_file = open('BosonNLP_sentiment_score.txt', 'r+', encoding='utf-8')  \n",
    "    # 获取字典文件内容  \n",
    "    print(sen_file)\n",
    "    sen_list = sen_file.readlines()  \n",
    "    # 创建情感字典  \n",
    "    print(sen_list)\n",
    "    sen_dict = defaultdict()  \n",
    "    # 读取字典文件每一行内容，将其转换为字典对象，key为情感词，value为对应的分值  \n",
    "    for s in sen_list:  \n",
    "        # 每一行内容根据空格分割，索引0是情感词，索引1是情感分值（情感词典文件中有一行是空行，因此执行的时候会报错，注意处理一下空行，这里没有处理）  \n",
    "        sen_dict[s.split(' ')[0]] = s.split(' ')[1]  \n",
    "  \n",
    "    # 读取否定词文件  \n",
    "    not_word_file = open('notDic.txt', 'r+', encoding='utf-8')  \n",
    "    # 由于否定词只有词，没有分值，使用list即可  \n",
    "    not_word_list = not_word_file.readlines()  \n",
    "  \n",
    "    # 读取程度副词文件  \n",
    "    degree_file = open('degree.txt', 'r+', encoding='utf-8')  \n",
    "    degree_list = degree_file.readlines()  \n",
    "    degree_dic = defaultdict()  \n",
    "    # 程度副词与情感词处理方式一样，转为程度副词字典对象，key为程度副词，value为对应的程度值  \n",
    "    for d in degree_list:  \n",
    "        degree_dic[d.split(',')[0]] = d.split(',')[1]  \n",
    "  \n",
    "    # 分类结果，词语的index作为key,词语的分值作为value，否定词分值设为-1  \n",
    "    sen_word = dict()  \n",
    "    not_word = dict()  \n",
    "    degree_word = dict()  \n",
    "\n",
    "#classifyWords(sent2word(\"总的来看总的来看遍历所有语料中的所有词语，删除其中的停用词。\"))\n",
    "\n",
    "classify_words(sent2word(\"总的来看总的来看遍历所有语料中的所有词语，删除其中的停用词。\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sen_file = open('BosonNLP_sentiment_score.txt', 'r+', encoding='utf-8')  \n",
    "    # 获取字典文件内容  \n",
    "print(sen_file)\n",
    "sen_list = sen_file.readlines()  \n",
    "    # 创建情感字典  \n",
    "print(sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac24e38eb2e4449ea71bf46a5c0b0eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "text = widgets.Text()\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    print(text.value)\n",
    "text.on_submit(handle_submit)\n",
    "button = widgets.Button(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "4",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
